{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning Bert\n",
    "\n",
    "In this notebook we try to replicate the results in [this Colab Notebook](https://colab.research.google.com/drive/1Nwvg3QaVW-OAFoi7cV-0sEnxFGsLbYqs). We start by loading the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "from urllib import request\n",
    "import time\n",
    "import datetime\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('../src'))\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 4\n",
    "BATCH_SIZE = 32\n",
    "MAXLEN = 64\n",
    "\n",
    "device = torch.device('cuda:1')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZIPFILE = 'cola_public_1.1.zip'\n",
    "DATAFOLDER = Path('../data')\n",
    "DESTFILE = DATAFOLDER/ZIPFILE\n",
    "RAWFOLDER = DATAFOLDER/'cola_public/raw'\n",
    "TRAINFILE = RAWFOLDER/'in_domain_train.tsv'\n",
    "TESTFILE = RAWFOLDER/'in_domain_dev.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
    "if not os.path.exists(DESTFILE):\n",
    "    request.urlretrieve(URL, DESTFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DATAFOLDER/'cola_public'):\n",
    "    with zipfile.ZipFile(DESTFILE, 'r') as zh:\n",
    "        zh.extractall(DATAFOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8551, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_source</th>\n",
       "      <th>label</th>\n",
       "      <th>label_notes</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gj04</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our friends won't buy this analysis, let alone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gj04</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One more pseudo generalization and I'm giving up.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gj04</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One more pseudo generalization or I'm giving up.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gj04</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The more we study verbs, the crazier they get.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gj04</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Day by day the facts are getting murkier.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence_source  label label_notes  \\\n",
       "0            gj04      1         NaN   \n",
       "1            gj04      1         NaN   \n",
       "2            gj04      1         NaN   \n",
       "3            gj04      1         NaN   \n",
       "4            gj04      1         NaN   \n",
       "\n",
       "                                            sentence  \n",
       "0  Our friends won't buy this analysis, let alone...  \n",
       "1  One more pseudo generalization and I'm giving up.  \n",
       "2   One more pseudo generalization or I'm giving up.  \n",
       "3     The more we study verbs, the crazier they get.  \n",
       "4          Day by day the facts are getting murkier.  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table(TRAINFILE, delimiter='\\t', header=None,\n",
    "                  names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6023\n",
       "0    2528\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there repeated sentences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['label', 'sentence']]\n",
    "df['sentence'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8543, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Our friends won't buy this analysis, let alone the next one we propose.\",\n",
       "       \"One more pseudo generalization and I'm giving up.\",\n",
       "       \"One more pseudo generalization or I'm giving up.\", ...,\n",
       "       'It is easy to slay the Gorgon.',\n",
       "       'I had the strangest feeling that I knew you.',\n",
       "       'What all did you get for Christmas?'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences, labels = df.sentence.values, df.label.values\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to repeat the operations above for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(527, 4)\n",
      "(527, 4)\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_table(TESTFILE, delimiter='\\t', header=None,\n",
    "                  names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
    "print(df_test.shape)\n",
    "df_test = df_test.drop_duplicates()\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences, test_labels = df_test.sentence, df_test.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lowercase=True)\n",
    "len(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tokenizer contains a `tokenize` function that does *not* add the special tokens. However, the `tokenizer.encode` function, does:\n",
    "\n",
    "1. Split the sentence into tokens.\n",
    "2. Add the special tokens.\n",
    "3. Map the tokens to integer indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['our',\n",
       " 'friends',\n",
       " 'won',\n",
       " \"'\",\n",
       " 't',\n",
       " 'buy',\n",
       " 'this',\n",
       " 'analysis',\n",
       " ',',\n",
       " 'let',\n",
       " 'alone',\n",
       " 'the',\n",
       " 'next',\n",
       " 'one',\n",
       " 'we',\n",
       " 'propose',\n",
       " '.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tokenizer.encode` function adds the special tokens `[SEP]`and `[CLS]`. The function in the `utils` module take also care of padding the encoded sequences with zeros. Note that it can also truncate sentences to a `MAXLEN` length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8543, 64) int64 (8543, 64) int64\n"
     ]
    }
   ],
   "source": [
    "inputs = utils.process_sentences(sentences, maxlen=MAXLEN)\n",
    "masks = utils.create_attention_mask(inputs)\n",
    "print(inputs.shape, inputs.dtype, masks.shape, masks.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(527, 64) (527, 64)\n"
     ]
    }
   ],
   "source": [
    "test_inputs = utils.process_sentences(test_sentences, maxlen=MAXLEN)\n",
    "test_masks = utils.create_attention_mask(test_inputs)\n",
    "print(test_inputs.shape, test_masks.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validation splits\n",
    "\n",
    "Let's create a training and a testidation set using Scikit-Learn functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7688, 64) (855, 64)\n",
      "(7688,) (855,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_inputs, val_inputs, train_labels, val_labels = train_test_split(\n",
    "    inputs, labels, random_state=42, test_size=0.1)\n",
    "\n",
    "train_masks, val_masks, _, _ = train_test_split(\n",
    "    masks, labels, random_state=42, test_size=0.1)\n",
    "\n",
    "print(train_inputs.shape, val_inputs.shape)\n",
    "print(train_labels.shape, val_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert these arrays into tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = torch.tensor(train_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "\n",
    "val_inputs = torch.tensor(val_inputs)\n",
    "val_labels = torch.tensor(val_labels)\n",
    "val_masks = torch.tensor(val_masks)\n",
    "\n",
    "test_inputs = torch.tensor(test_inputs)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "test_masks = torch.tensor(test_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, sampler=RandomSampler(train_data), batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(val_data, sampler=SequentialSampler(val_data), batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_data, sampler=SequentialSampler(test_data), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8)\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    241.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    241.    Elapsed: 0:00:17.\n",
      "  Batch   120  of    241.    Elapsed: 0:00:26.\n",
      "  Batch   160  of    241.    Elapsed: 0:00:35.\n",
      "  Batch   200  of    241.    Elapsed: 0:00:44.\n",
      "  Batch   240  of    241.    Elapsed: 0:00:52.\n",
      "\n",
      "  Average training loss: 0.61\n",
      "  Training epcoh took: 0:00:52\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.72\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    241.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    241.    Elapsed: 0:00:18.\n",
      "  Batch   120  of    241.    Elapsed: 0:00:26.\n",
      "  Batch   160  of    241.    Elapsed: 0:00:35.\n",
      "  Batch   200  of    241.    Elapsed: 0:00:44.\n",
      "  Batch   240  of    241.    Elapsed: 0:00:53.\n",
      "\n",
      "  Average training loss: 0.61\n",
      "  Training epcoh took: 0:00:53\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.72\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    241.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    241.    Elapsed: 0:00:18.\n",
      "  Batch   120  of    241.    Elapsed: 0:00:27.\n",
      "  Batch   160  of    241.    Elapsed: 0:00:36.\n",
      "  Batch   200  of    241.    Elapsed: 0:00:45.\n",
      "  Batch   240  of    241.    Elapsed: 0:00:54.\n",
      "\n",
      "  Average training loss: 0.61\n",
      "  Training epcoh took: 0:00:54\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.72\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    241.    Elapsed: 0:00:09.\n",
      "  Batch    80  of    241.    Elapsed: 0:00:18.\n",
      "  Batch   120  of    241.    Elapsed: 0:00:27.\n",
      "  Batch   160  of    241.    Elapsed: 0:00:36.\n",
      "  Batch   200  of    241.    Elapsed: 0:00:45.\n",
      "  Batch   240  of    241.    Elapsed: 0:00:54.\n",
      "\n",
      "  Average training loss: 0.61\n",
      "  Training epcoh took: 0:00:54\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.72\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "model.zero_grad()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, EPOCHS):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, EPOCHS))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    # Set our model to training mode (as opposed to evaluation mode)\n",
    "    model.train()\n",
    "        \n",
    "    # This training code is based on the `run_glue.py` script here:\n",
    "    # https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_loader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = utils.format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(\n",
    "                step, len(train_loader), elapsed))\n",
    "\n",
    "        # Put the model into training mode.    \n",
    "        model.train()\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "                \n",
    "        # Forward pass (evaluate the model on this training batch)\n",
    "        # `model` is of type: pytorch_pretrained_bert.modeling.BertForSequenceClassification\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Accumulate the loss. `loss` is a Tensor containing a single value; \n",
    "        # the `.item()` function just returns the Python value from the tensor.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "        # Clear out the gradients (by default they accumulate)\n",
    "        model.zero_grad()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_loader)            \n",
    "    \n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(utils.format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put model in evaluation mode to evaluate loss on the validation set\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in val_loader:\n",
    "        \n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
    "        with torch.no_grad():        \n",
    "            # Forward pass, calculate logit predictions\n",
    "            # token_type_ids is for the segment ids, but we only have a single sentence here.\n",
    "            # See https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L258 \n",
    "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "        \n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        tmp_eval_accuracy = utils.flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(utils.format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
